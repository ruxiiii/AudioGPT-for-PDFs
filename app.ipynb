{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aarus\\Documents\\Code\\tensorgo\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from faster_whisper import WhisperModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "from groq import Groq\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language 'hi' with probability 0.794072\n",
      "[0.00s -> 8.86s]  जक्मों के साथ ही हम साथ साथ हैं\n",
      "Sure, I'd be happy to help you translate the Hindi text \"जक्मों के साथ ही हम साथ साथ हैं\" into English.\n",
      "\n",
      "The translation of \"जक्मों के साथ ही हम साथ साथ हैं\" in English is \"We are with them and with each other.\"\n",
      "\n",
      "Here's how I arrived at that translation:\n",
      "\n",
      "* \"जक्मों\" is a plural form of the word \"जक्म\", which means \"companion\" or \"associate\".\n",
      "* \"के साथ\" means \"with\".\n",
      "* \"ही\" is a word that is used for emphasis and can be translated to \"even\", \"also\", or \"too\".\n",
      "* \"हम\" is the first person plural pronoun, which means \"we\".\n",
      "* \"साथ साथ\" means \"together\".\n",
      "\n",
      "Putting all of those words together, we get \"We are with them and with each other.\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# GROQ_API_KEY = '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'\n",
    "\n",
    "\n",
    "\n",
    "def translator(client, text_input, detected_language, model_name):\n",
    "  prompt = f'''\n",
    "    You are a language translator, you'll get a text input : {text_input} and the detected language of the text :  {detected_language}. Your job is to translate the text input into english. For example :\n",
    "\n",
    "    When the detected language is French, and the text input is 'J'aime programmer' then the output in English is supposed to be 'I love Programming'\n",
    "\n",
    "  '''.format(text_input = text_input, detected_language=detected_language)\n",
    "  return groq_chat(client, prompt, model_name, None)\n",
    "\n",
    "def groq_chat(client, prompt,  model, response_format):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "\n",
    "        response_format=response_format\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "model_size = 'medium'\n",
    "    # if whisper_model is None:\n",
    "    #             whisper_model = WhisperModel.load_model(\"medium\", download_root=os.path.join(os.getcwd(), \"your_custom_dir\"))\n",
    "\n",
    "    # local_model_path = 'C:/Users/aarus/Documents/Whisper-Faster/.cache/hub/models--Systran--faster-whisper-medium/snapshots/08e178d48790749d25932bbc082711ddcfdfbc4f'\n",
    "\n",
    "model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\", local_files_only=True)\n",
    "\n",
    "    #\"C:\\Users\\aarus\\Documents\\Sound Recordings\\ProjectAudio.m4a\"\n",
    "\n",
    "segments, info = model.transcribe(\"C:/Users/aarus/Documents/Sound Recordings/Recording (6).m4a\", beam_size=5)\n",
    "print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n",
    "\n",
    "final_text = ''\n",
    "for segment in segments:\n",
    "        print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))\n",
    "        final_text += segment.text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_name = 'mixtral-8x7b-32768'\n",
    "groq_api_key = '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'\n",
    "\n",
    "\n",
    "text_input = final_text\n",
    "detected_language = info.language\n",
    "\n",
    "client = Groq(\n",
    "        api_key = groq_api_key\n",
    "    )\n",
    "\n",
    "llm_response = translator(client, text_input, detected_language, model_name)\n",
    "print(llm_response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "\n",
    "def get_text_chunks(text):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        # separator=\"\\n\",\n",
    "        chunk_size=150,\n",
    "        chunk_overlap=50,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False\n",
    "    )\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks\n",
    "\n",
    "def get_vectorstore(text_chunks):\n",
    "    embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "    vectorstore = FAISS.from_texts(texts=text_chunks, embedding=embeddings)\n",
    "    return vectorstore\n",
    "\n",
    "\n",
    "def get_relevant_excerpts(user_question, vectorstore):\n",
    "\n",
    "  relevent_docs = vectorstore.similarity_search(user_question)\n",
    "  return relevent_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size_or_path =  'C:/Users/aarus/.cache/huggingface/hub/models--Systran--faster-whisper-medium/snapshots08e178d48790749d25932bbc082711ddcfdfbc4f'\n",
    "\n",
    "#geetanjali enclave\n",
    "#khidki extension, opposite triveni\n",
    "#greater kailash\n",
    "\n",
    "model = WhisperModel(model_size_or_path='medium', local_files_only=True, device='cpu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
